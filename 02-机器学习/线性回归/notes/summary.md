# 线性回归 — 关键点总结

---

## 一、代码实现关键点

### 底层实现（手写梯度下降）

- `X.shape` 获取数据形状 → (样本数, 特征数)
- `np.dot(X, w)` 矩阵乘法，一次性算出所有样本的预测值
- `np.dot(X.T, error)` 转置后点乘误差 → 一次性算出所有权重的梯度
- `y` 必须是**一维数组**，二维会导致维度广播出错，用 `.flatten()` 展平
- 损失曲线呈 "L" 形 = 正常收敛；最终 MSE ≠ 0 是因为数据中有噪声

### 调库实现（sklearn）

- `LinearRegression().fit(X, y)` 一行训练，内部用正规方程求解
- `model.coef_` → 权重 w，`model.intercept_` → 偏置 b（带 `_` 表示训练后才有）
- `StandardScaler`：`fit_transform` 用于训练集，`transform` 用于测试集（用同一套均值/标准差）

### 评估指标

- **MSE**：误差绝对大小，越小越好
- **R²**：模型解释了多少比例的变化，越接近 1 越好

---

## 二、线性回归实战步骤模板

```
1. 加载数据
   ↓
2. 划分训练集 / 测试集（如 80% / 20%）
   ↓
3. 数据标准化（StandardScaler）
   - 训练集: fit_transform（学习 + 转换）
   - 测试集: transform（只转换，用训练集的参数）
   ↓
4. 创建模型 & 训练
   - 手写版: 设置学习率和迭代次数，梯度下降
   - 调库版: LinearRegression().fit()
   ↓
5. 预测
   - 分别对训练集和测试集预测
   ↓
6. 评估模型
   - 计算 MSE 和 R²
   - 对比训练集 vs 测试集（差距大 = 过拟合）
   ↓
7. 可视化（可选）
   - 散点图 + 预测线
   - 损失下降曲线（手写版）
```

---

## 三、容易踩的坑

| 问题 | 原因 | 解决 |
|------|------|------|
| 维度不匹配报错 | y 是二维 (n,1) 而不是一维 (n,) | `.flatten()` 展平 |
| 梯度下降不收敛 | 学习率太大 | 调小 α（试 0.01, 0.001） |
| 中文显示方块 | matplotlib 不支持中文 | `plt.rcParams['font.sans-serif'] = ['SimHei']` |
| 测试集标准化错误 | 对测试集也用了 fit_transform | 测试集只用 `transform` |

---

*📅 总结日期：2026-02-25*
